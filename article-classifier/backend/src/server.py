import torch
import torch.nn.functional as F
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from torch_geometric.datasets import Planetoid
import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Import kiáº¿n trÃºc mÃ´ hÃ¬nh GCN
from model.gcn import GCN

# ðŸ”¹ Load dataset (Cora)
dataset = Planetoid(root="data", name="Cora")

# Láº¥y sá»‘ feature vÃ  sá»‘ lá»›p tá»« dataset
num_features = dataset.num_node_features
num_classes = dataset.num_classes

# Danh sÃ¡ch tÃªn class tÆ°Æ¡ng á»©ng vá»›i táº­p Cora
class_names = [
    "Case-Based",               # Class 0
    "Genetic Algorithms",       # Class 1
    "Neural Networks",          # Class 2
    "Probabilistic Methods",    # Class 3
    "Reinforcement Learning",   # Class 4
    "Rule Learning",            # Class 5
    "Theory"                    # Class 6
]

# ðŸ”¹ Khá»Ÿi táº¡o FastAPI
app = FastAPI()

# ðŸ”¹ Cáº¥u hÃ¬nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ðŸ”¹ Táº£i mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
device = torch.device("cpu")
model_path = os.path.join(os.path.dirname(__file__), "../model/gcn_model.pth")

# ðŸ›  Khá»Ÿi táº¡o model vá»›i sá»‘ feature vÃ  sá»‘ class Ä‘Ãºng
model = GCN(num_features=num_features, hidden_channels=16, num_classes=num_classes)

# ðŸ›  Load trá»ng sá»‘
model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device)
model.eval()

# ðŸ”¹ Lá»›p nháº­n dá»¯ liá»‡u Ä‘áº§u vÃ o
class PaperInput(BaseModel):
    title: str

# ðŸ”¹ Dá»¯ liá»‡u Ä‘á»“ thá»‹ tá»« táº­p Cora
data = dataset[0]
features = data.x.clone().to(device)  # Sao chÃ©p Ä‘áº·c trÆ°ng gá»‘c
edge_index = data.edge_index.clone().to(device)  # Sao chÃ©p Ä‘á»“ thá»‹ gá»‘c

@app.post("/predict")
async def predict_paper(paper: PaperInput):
    global features, edge_index  # Cáº­p nháº­t global Ä‘á»ƒ thÃªm nÃºt má»›i

    title = paper.title.strip()
    if not title:
        raise HTTPException(status_code=400, detail="Vui lÃ²ng cung cáº¥p tiÃªu Ä‘á» bÃ i bÃ¡o!")

    # ðŸ›  Táº¡o vector Ä‘áº·c trÆ°ng ngáº«u nhiÃªn (thay tháº¿ báº±ng embedding thá»±c táº¿ náº¿u cÃ³)
    new_feature = torch.randn(1, num_features).to(device)  # (1, d)

    # ðŸ›  ThÃªm vÃ o danh sÃ¡ch Ä‘áº·c trÆ°ng
    N = features.shape[0]  # Sá»‘ nÃºt hiá»‡n cÃ³
    features = torch.cat([features, new_feature], dim=0)  # (N+1, d)

    # ðŸ›  Káº¿t ná»‘i vá»›i nÃºt gáº§n nháº¥t báº±ng cosine similarity
    similarities = torch.cosine_similarity(new_feature, features[:-1], dim=1)
    existing_node_index = torch.argmax(similarities).item()

    # ðŸ›  Cáº­p nháº­t táº­p cáº¡nh `edge_index`
    new_edge = torch.tensor([[existing_node_index], [N]], dtype=torch.long, device=device)
    edge_index = torch.cat([edge_index, new_edge], dim=1)  # ThÃªm liÃªn káº¿t má»›i

    # ðŸ”¹ Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh GCN
    with torch.no_grad():
        output = model(features, edge_index)
        if N >= output.shape[0]:  # Kiá»ƒm tra lá»—i chá»‰ má»¥c
            raise HTTPException(status_code=500, detail="Lá»—i: chá»‰ sá»‘ nÃºt vÆ°á»£t quÃ¡ pháº¡m vi.")

        probabilities = F.softmax(output[N], dim=0)  # Láº¥y xÃ¡c suáº¥t cá»§a nÃºt má»›i

    # ðŸ”¹ Kiá»ƒm tra káº¿t quáº£ dá»± Ä‘oÃ¡n
    if probabilities.numel() != num_classes:
        raise HTTPException(status_code=500, detail="Lá»—i: Sá»‘ lÆ°á»£ng lá»›p dá»± Ä‘oÃ¡n khÃ´ng khá»›p.")

    # ðŸ”¹ Láº¥y top 3 dá»± Ä‘oÃ¡n
    top_probs, top_classes = torch.topk(probabilities, min(3, num_classes))
    predictions = [
        {
            "class": class_names[int(c.item())],  # GÃ¡n tÃªn class thay vÃ¬ sá»‘
            "confidence": round(float(p.item()) * 100, 2)
        }
        for p, c in zip(top_probs, top_classes)
    ]

    return {"title": title, "predictions": predictions}